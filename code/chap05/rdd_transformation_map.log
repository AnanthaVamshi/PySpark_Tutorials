./bin/spark-submit rdd_transformation_map.py

spark= <pyspark.sql.session.SparkSession object at 0x1090b6450>

list_of_tuples =  
[
 ('alex', 'Sunnyvale', 25), 
 ('alex', 'Sunnyvale', 33), 
 ('mary', 'Ames', 22), 
 ('mary', 'Cupertino', 66), 
 ('jane', 'Ames', 20), 
 ('bob', 'Ames', 26)
]

rdd =  ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:175
rdd.count() =  6
rdd.collect() =  
[
 ('alex', 'Sunnyvale', 25), 
 ('alex', 'Sunnyvale', 33), 
 ('mary', 'Ames', 22), 
 ('mary', 'Cupertino', 66), 
 ('jane', 'Ames', 20), 
 ('bob', 'Ames', 26)
]


rdd2 =  PythonRDD[2] at RDD at PythonRDD.scala:48
rdd2.count() =  6
rdd2.collect() =  
[
 ('alex', 25), 
 ('alex', 33), 
 ('mary', 22), 
 ('mary', 66), 
 ('jane', 20), 
 ('bob', 26)
]

rdd3 =  PythonRDD[4] at RDD at PythonRDD.scala:48
rdd3.count() =  6
rdd3.collect() =  
[
 ('Sunnyvale', ('alex', 'Sunnyvale', 25)), 
 ('Sunnyvale', ('alex', 'Sunnyvale', 33)), 
 ('Ames', ('mary', 'Ames', 22)), 
 ('Cupertino', ('mary', 'Cupertino', 66)), 
 ('Ames', ('jane', 'Ames', 20)), 
 ('Ames', ('bob', 'Ames', 26))
]
