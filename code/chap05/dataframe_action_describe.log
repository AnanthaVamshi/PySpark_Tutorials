./bin/spark-submit dataframe_action_describe.py

spark= <pyspark.sql.session.SparkSession object at 0x107c01cd0>

pairs =  
[
 (10, 'z1'), 
 (1, 'z2'), 
 (2, 'z3'), 
 (9, 'z4'), 
 (3, 'z5'), 
 (4, 'z6'), 
 (5, 'z7'), 
 (6, 'z8'), 
 (7, 'z9')
]

df.count():  9
df.collect():  
[
 Row(number=10, name=u'z1'), 
 Row(number=1, name=u'z2'), 
 Row(number=2, name=u'z3'), 
 Row(number=9, name=u'z4'), 
 Row(number=3, name=u'z5'), 
 Row(number=4, name=u'z6'), 
 Row(number=5, name=u'z7'), 
 Row(number=6, name=u'z8'), 
 Row(number=7, name=u'z9')
]

+------+----+
|number|name|
+------+----+
|    10|  z1|
|     1|  z2|
|     2|  z3|
|     9|  z4|
|     3|  z5|
|     4|  z6|
|     5|  z7|
|     6|  z8|
|     7|  z9|
+------+----+

+-------+------------------+
|summary|            number|
+-------+------------------+
|  count|                 9|
|   mean| 5.222222222222222|
| stddev|3.0731814857642954|
|    min|                 1|
|    max|                10|
+-------+------------------+

+-------+------------------+----+
|summary|            number|name|
+-------+------------------+----+
|  count|                 9|   9|
|   mean| 5.222222222222222|null|
| stddev|3.0731814857642954|null|
|    min|                 1|  z1|
|    max|                10|  z9|
+-------+------------------+----+
