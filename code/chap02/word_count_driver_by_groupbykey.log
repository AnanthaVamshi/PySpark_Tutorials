./bin/spark-submit word_count_driver_by_groupbykey.py sample_file.txt

input_path: sample_file.txt

records.count():  3

records.collect():  
[
 u'red fox jumped high and high', 
 u'red fox jumped high fence', 
 u'fox jumped'
]

non_empty_records.count():  3

non_empty_records.collect():  
[
 u'red fox jumped high and high', 
 u'red fox jumped high fence', 
 u'fox jumped'
]

words.count():  13

words.collect():  
[
 u'red', 
 u'fox', 
 u'jumped', 
 u'high', 
 u'and', 
 u'high', 
 u'red', 
 u'fox', 
 u'jumped', 
 u'high', 
 u'fence', 
 u'fox', 
 u'jumped'
]

pairs.count():  13

pairs.collect():  
[
 (u'red', 1), 
 (u'fox', 1), 
 (u'jumped', 1), 
 (u'high', 1), 
 (u'and', 1), 
 (u'high', 1), 
 (u'red', 1), 
 (u'fox', 1), 
 (u'jumped', 1), 
 (u'high', 1), 
 (u'fence', 1), 
 (u'fox', 1), 
 (u'jumped', 1)
]

grouped_by_unique_words.count():  6

grouped_by_unique_words.collect():  
[
 (u'and', <pyspark.resultiterable.ResultIterable object at 0x10ce49810>), 
 (u'high', <pyspark.resultiterable.ResultIterable object at 0x10d3fb310>), 
 (u'fox', <pyspark.resultiterable.ResultIterable object at 0x10d3fb390>), 
 (u'red', <pyspark.resultiterable.ResultIterable object at 0x10ce497d0>), 
 (u'fence', <pyspark.resultiterable.ResultIterable object at 0x10ce49850>), 
 (u'jumped', <pyspark.resultiterable.ResultIterable object at 0x10ce49f50>)
]

frequencies.count():  6

frequencies.collect():  
[
 (u'and', 1), 
 (u'high', 3), 
 (u'fox', 3), 
 (u'red', 2), 
 (u'fence', 1), 
 (u'jumped', 3)
]
