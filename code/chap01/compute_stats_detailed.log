# define python3: find out where python3 is installed?
$ type python3
python3 is /usr/local/bin/python3
$ /usr/local/bin/python3 --version
Python 3.7.1
export PYSPARK_PYTHON=/usr/local/bin/python3
#
# define PySpark program
export PROG="/pyspark_book/code/chap01/compute_stats_detailed.py"
# define your input path
export INPUT="/pyspark_book/code/chap01/url_frequencies.txt"
# define your Spark home directory
export SPARK_HOME="/pyspark_book/spark-2.4.3"
# run the program
$SPARK_HOME/bin/spark-submit $PROG $INPUT

input path : /pyspark_book/code/chap01/url_frequencies.txt

records :  
[
 'url1,1', 
 'url1,9', 
 'url1,4', 
 'ur,5', 
 'url1,8', 
 'url1,12', 
 'url2,2', 
 'url2,6', 
 'ur,2', 
 'url2,10', 
 'url2,6', 
 'url3,1', 
 'url3,10', 
 'url3,20', 
 'url3,30', 
 'url3,40', 
 'url3,50', 
 'url3,2',
 'url4,1',
 'url4,2'
]

filtered :  
[
 'url1,1', 
 'url1,9', 
 'url1,4', 
 'url1,8', 
 'url1,12', 
 'url2,2', 
 'url2,6', 
 'url2,10', 
 'url2,6', 
 'url3,1', 
 'url3,10', 
 'url3,20', 
 'url3,30', 
 'url3,40', 
 'url3,50', 
 'url3,2',
 'url4,1',
 'url4,2'
]

pairs :  
[
 ('url1', 1), 
 ('url1', 9), 
 ('url1', 4), 
 ('url1', 8), 
 ('url1', 12), 
 ('url2', 2), 
 ('url2', 6), 
 ('url2', 10), 
 ('url2', 6), 
 ('url3', 1), 
 ('url3', 10), 
 ('url3', 20), 
 ('url3', 30), 
 ('url3', 40), 
 ('url3', 50), 
 ('url3', 2),
 ('url4', 1),
 ('url4', 2), 
]

grouped :  
[
 ('url3', [1, 10, 20, 30, 40, 50, 2]), 
 ('url1', [1, 9, 4, 8, 12]), 
 ('url2', [2, 6, 10, 6]),
 ('url4', [1, 2])
]

results =  
[
 ('url3', (21.857142857142858, 20, 18.97743020387263)), 
 ('url1', (6.8, 8, 4.324349662087931)), 
 ('url2', (6, 6.0, 3.265986323710904)),
 ('url4', (1.5, 1.5, 0.7071067811865476))
]
